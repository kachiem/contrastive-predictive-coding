{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exploring MnistHandler, MnistGenerator, and SortedNumberGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistHandler(object):\n",
    "\n",
    "    ''' Provides a convenient interface to manipulate MNIST data '''\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Download data if needed\n",
    "        self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test = self.load_dataset()\n",
    "\n",
    "        # Load Lena image to memory\n",
    "        self.lena = Image.open('../resources/lena.jpg')\n",
    "\n",
    "    def load_dataset(self):\n",
    "        # Credit for this function: https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py\n",
    "\n",
    "        # We first define a download function, supporting both Python 2 and 3.\n",
    "        if sys.version_info[0] == 2:\n",
    "            from urllib import urlretrieve\n",
    "        else:\n",
    "            #from urllib.request import urlretrieve\n",
    "            import requests\n",
    "\n",
    "        def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "            print(\"Downloading %s\" % filename)\n",
    "            requests.get(source + filename, filename)\n",
    "\n",
    "        # We then define functions for loading MNIST images and labels.\n",
    "        # For convenience, they also download the requested files if needed.\n",
    "        import gzip\n",
    "\n",
    "        def load_mnist_images(filename):\n",
    "            if not os.path.exists(filename):\n",
    "                download(filename)\n",
    "            # Read the inputs in Yann LeCun's binary format.\n",
    "            with gzip.open(filename, 'rb') as f:\n",
    "                data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "            # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "            # following the shape convention: (examples, channels, rows, columns)\n",
    "            data = data.reshape(-1, 1, 28, 28)\n",
    "            # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "            # (Actually to range [0, 255/256], for compatibility to the version\n",
    "            # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "            return data / np.float32(256)\n",
    "\n",
    "        def load_mnist_labels(filename):\n",
    "            if not os.path.exists(filename):\n",
    "                download(filename)\n",
    "            # Read the labels in Yann LeCun's binary format.\n",
    "            with gzip.open(filename, 'rb') as f:\n",
    "                data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "            # The labels are vectors of integers now, that's exactly what we want.\n",
    "            return data\n",
    "\n",
    "        # We can now download and read the training and test set images and labels.\n",
    "        X_train = load_mnist_images('../resources/train-images-idx3-ubyte.gz')\n",
    "        y_train = load_mnist_labels('../resources/train-labels-idx1-ubyte.gz')\n",
    "        X_test = load_mnist_images('../resources/t10k-images-idx3-ubyte.gz')\n",
    "        y_test = load_mnist_labels('../resources/t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "        # We reserve the last 10000 training examples for validation.\n",
    "        X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "        y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "        # We just return all the arrays in order, as expected in main().\n",
    "        # (It doesn't matter how we do this as long as we can read them again.)\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "    def process_batch(self, batch, batch_size, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Resize from 28x28 to 64x64\n",
    "        if image_size == 64:\n",
    "            batch_resized = []\n",
    "            for i in range(batch.shape[0]):\n",
    "                # resize to 64x64 pixels\n",
    "                batch_resized.append(scipy.ndimage.zoom(batch[i, :, :], 2.3, order=1))\n",
    "            batch = np.stack(batch_resized)\n",
    "\n",
    "        # Convert to RGB\n",
    "        batch = batch.reshape((batch_size, 1, image_size, image_size))\n",
    "        batch = np.concatenate([batch, batch, batch], axis=1)\n",
    "\n",
    "        # Modify images if color distribution requested\n",
    "        if color:\n",
    "\n",
    "            # Binarize images\n",
    "            batch[batch >= 0.5] = 1\n",
    "            batch[batch < 0.5] = 0\n",
    "\n",
    "            # For each image in the mini batch\n",
    "            for i in range(batch_size):\n",
    "\n",
    "                # Take a random crop of the Lena image (background)\n",
    "                x_c = np.random.randint(0, self.lena.size[0] - image_size)\n",
    "                y_c = np.random.randint(0, self.lena.size[1] - image_size)\n",
    "                image = self.lena.crop((x_c, y_c, x_c + image_size, y_c + image_size))\n",
    "                image = np.asarray(image).transpose((2, 0, 1)) / 255.0\n",
    "\n",
    "                # Randomly alter the color distribution of the crop\n",
    "                for j in range(3):\n",
    "                    image[j, :, :] = (image[j, :, :] + np.random.uniform(0, 1)) / 2.0\n",
    "\n",
    "                # Invert the color of pixels where there is a number\n",
    "                image[batch[i, :, :, :] == 1] = 1 - image[batch[i, :, :, :] == 1]\n",
    "                batch[i, :, :, :] = image\n",
    "\n",
    "        # Rescale to range [-1, +1]\n",
    "        if rescale:\n",
    "            batch = batch * 2 - 1\n",
    "\n",
    "        # Channel last\n",
    "        batch = batch.transpose((0, 2, 3, 1))\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def get_batch(self, subset, batch_size, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Select a subset\n",
    "        if subset == 'train':\n",
    "            X = self.X_train\n",
    "            y = self.y_train\n",
    "        elif subset == 'valid':\n",
    "            X = self.X_val\n",
    "            y = self.y_val\n",
    "        elif subset == 'test':\n",
    "            X = self.X_test\n",
    "            y = self.y_test\n",
    "\n",
    "        # Random choice of samples\n",
    "        idx = np.random.choice(X.shape[0], batch_size)\n",
    "        batch = X[idx, 0, :].reshape((batch_size, 28, 28))\n",
    "\n",
    "        # Process batch\n",
    "        batch = self.process_batch(batch, batch_size, image_size, color, rescale)\n",
    "\n",
    "        # Image label\n",
    "        labels = y[idx]\n",
    "\n",
    "        return batch.astype('float32'), labels.astype('int32')\n",
    "\n",
    "    def get_batch_by_labels(self, subset, labels, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Select a subset\n",
    "        if subset == 'train':\n",
    "            X = self.X_train\n",
    "            y = self.y_train\n",
    "        elif subset == 'valid':\n",
    "            X = self.X_val\n",
    "            y = self.y_val\n",
    "        elif subset == 'test':\n",
    "            X = self.X_test\n",
    "            y = self.y_test\n",
    "\n",
    "        # Find samples matching labels\n",
    "        idxs = []\n",
    "        for i, label in enumerate(labels):\n",
    "\n",
    "            idx = np.where(y == label)[0]\n",
    "            idx_sel = np.random.choice(idx, 1)[0]\n",
    "            idxs.append(idx_sel)\n",
    "\n",
    "        # Retrieve images\n",
    "        batch = X[np.array(idxs), 0, :].reshape((len(labels), 28, 28))\n",
    "\n",
    "        # Process batch\n",
    "        batch = self.process_batch(batch, len(labels), image_size, color, rescale)\n",
    "\n",
    "        return batch.astype('float32'), labels.astype('int32')\n",
    "\n",
    "    def get_n_samples(self, subset):\n",
    "\n",
    "        if subset == 'train':\n",
    "            y_len = self.y_train.shape[0]\n",
    "        elif subset == 'valid':\n",
    "            y_len = self.y_val.shape[0]\n",
    "        elif subset == 'test':\n",
    "            y_len = self.y_test.shape[0]\n",
    "\n",
    "        return y_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemmapHandler(object):\n",
    "    ''' making and saving memmaps '''\n",
    "    def __init__(self, folder, n_lags, spect_height, subset):\n",
    "        # spect_height = number of freq. bins\n",
    "        # y always has one time bin\n",
    "        # n_lags is number of time bins of x\n",
    "        # shape of x = (n_lags,spect_height) x number of samples\n",
    "        # shape of y = (1, spect_height) x number of samples\n",
    "        \n",
    "        # input variables\n",
    "        self.folder = folder  # either datafolder or visfolder\n",
    "        self.n_lags = n_lags\n",
    "        self.spect_height = spect_height\n",
    "        self.subset = subset  # datafolder: use train/valid\n",
    "                              # visfolder: use test\n",
    "        \n",
    "        # generated variables\n",
    "        self.NIN = self.n_lags*self.spect_height\n",
    "        data = self.init_data(folder, 'y.npy')\n",
    "        self.num_data_samples = self.get_n_samples(self.subset)\n",
    "        self.shape = (n_lags*spect_height, self.num_data_samples)\n",
    "        \n",
    "        \n",
    "        def init_data(self, folder, name, data):\n",
    "            ''' Create intitial stimulus and stimulus_vis memmaps '''\n",
    "            from pathlib import Path\n",
    "            data_file = Path(folder + name)\n",
    "            \n",
    "            if data_file.is_file():\n",
    "                data = load_memmap(data)\n",
    "            else:\n",
    "                data = generate_memmap(data)\n",
    "            return data\n",
    "        \n",
    "        def get_n_samples(self, data, subset):\n",
    "            ''' function to get number of samples in subset '''\n",
    "            if subset == 'train':\n",
    "                return int(len(data) / self.spect_height)\n",
    "            elif subset == 'valid':\n",
    "                return int(len(data) / self.spect_height)\n",
    "            elif subset == 'test':\n",
    "                return int(len(data) / self.spect_height)\n",
    "        \n",
    "        def read_file_loc(self, folder, n_lags):\n",
    "            ''' function to read in name of .dat file '''\n",
    "            loc = '%sx_lag%03d.dat' % (folder, n_lags)\n",
    "            return loc\n",
    "        \n",
    "        def generate_memmap(self, data, shape):\n",
    "            new_map = np.memmap(data, dtype='float32', mode='r', shape=shape)\n",
    "            return new_map\n",
    "        \n",
    "        def save_memmap(self, folder, filename, data):\n",
    "            memmap = np.save(folder + filename, data)\n",
    "            return memmap\n",
    "            \n",
    "        def load_memmap(self, data):\n",
    "            saved_map = np.lib.format.open_memmap(data, dtype='float32', mode='r', shape=shape)\n",
    "            return saved_map\n",
    "            \n",
    "        def memmap_copy(self, memmap_in, start_idx, end_idx):\n",
    "            ''' function to copy memmap and save ram !! '''\n",
    "            memmap_copy = memmap_in[:]\n",
    "            subset = memmap_copy[start_idx, end_idx]\n",
    "            return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted for subset\n",
    "class Shuffled_memmap_subset(object):\n",
    "    \n",
    "    ''' For creating train/valid/test shuffled memmap dataset '''\n",
    "    \n",
    "    def __init__(self, folder, subset, saved_data, vis_ratio=0, valid_ratio=.06):\n",
    "        \n",
    "        # Set params\n",
    "        self.folder = folder\n",
    "        self.subset = subset\n",
    "        self.saved_data = saved_data  # filename as string, eg. 'data.npy'\n",
    "\n",
    "        # Initialize memmap handler\n",
    "        self.memmap_handler = MemmapHandler()\n",
    "        \n",
    "        # Initialize data\n",
    "        data_loc = self.memmap_handler.read_file_loc(self.folder)\n",
    "        data = self.memmap_handler.init_data(self.folder, self.saved_data, x_location)\n",
    "        self.num_data_samples = self.memmap_handler.get_n_samples('train')\n",
    "        self.dataset = data.memmap_copy(data, data.shape[0], data.shape[1][:1000])\n",
    "    \n",
    "        # get dataset+batching indicies\n",
    "        #self.num_vis_samples = int(self.num_data_samples*vis_ratio)\n",
    "        self.num_valid_samples = int(self.num_data_samples*valid_ratio)\n",
    "        #vis_start = np.random.randint(self.num_data_samples - self.num_vis_samples)\n",
    "       \n",
    "        #self.vis_idxs = np.arange(vis_start, vis_start + self.num_vis_samples)\n",
    "        #self.data_idxs = np.delete(np.arange(self.num_data_samples), self.vis_idxs)\n",
    "        self.data_idxs_vis = np.arange(self.num_data_samples_vis)\n",
    "        self.data_idxs = np.arange(self.num_data_samples)\n",
    "        #self.num_data_samples -= self.num_vis_samples\n",
    "       \n",
    "        np.random.shuffle(self.data_idxs)\n",
    "        self.valid_idxs, self.data_idxs = np.split(self.data_idxs, [self.num_valid_samples])\n",
    "        self.num_data_samples -= self.num_valid_samples\n",
    "    \n",
    "    \n",
    "    def get_num_samples(self, subset):\n",
    "        ''' \n",
    "        Return number of samples wrt subset. \n",
    "            subset: a string - 'train', 'valid', or 'test'\n",
    "        '''\n",
    "        if subset == 'train':\n",
    "            return self.num_data_samples\n",
    "        elif subset == 'valid':\n",
    "            return self.num_valid_samples\n",
    "        elif subset == 'test':\n",
    "            return self.num_data_samples_vis\n",
    "    \n",
    "    def get_data(self, idx):\n",
    "        return self.x_data[:, idx].T, self.y_data[:, idx].T\n",
    "   \n",
    "    def data_iterator(self, batch_size=64):\n",
    "        np.random.shuffle(self.data_idxs)\n",
    "        for batch_idx in range(0, self.num_data_samples, batch_size):\n",
    "            shuff_idx = self.data_idxs[batch_idx:batch_idx+batch_size]\n",
    "            yield self.get_data(shuff_idx)\n",
    "   \n",
    "    def valid_set(self):\n",
    "        return self.get_data(self.valid_idxs)\n",
    "   \n",
    "    def valid_iterator(self, batch_size=64):\n",
    "        for batch_idx in range(0, self.num_valid_samples, batch_size):\n",
    "            valid_idx = self.valid_idxs[batch_idx:batch_idx+batch_size]\n",
    "            yield self.get_data(valid_idx)\n",
    "   \n",
    "    def vis_set(self):\n",
    "        #return self.get_data(self.vis_idxs)\n",
    "        return self.get_data(self.data_idxs_vis)\n",
    "   \n",
    "    #def vis_iterator(self, start=0, end=None, batch_size=1):\n",
    "    #    if end is None:\n",
    "    #        end = self.num_vis_samples\n",
    "    #    for batch_idx in range(start, end, batch_size):\n",
    "    #        data_idx = self.vis_idxs[batch_idx:batch_idx+batch_size]\n",
    "    #        yield self.get_data(data_idx)\n",
    "           \n",
    "    def vis_iterator(self, start=0, end=None, batch_size=1):\n",
    "        if end is None:\n",
    "            end = self.num_data_samples_vis\n",
    "        for batch_idx in range(start, end, batch_size):\n",
    "            data_idx = self.data_idxs_vis[batch_idx:batch_idx+batch_size]\n",
    "            yield self.get_data(data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistGenerator(object):\n",
    "\n",
    "    ''' Data generator providing MNIST data '''\n",
    "\n",
    "    def __init__(self, batch_size, subset, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Set params\n",
    "        self.batch_size = batch_size\n",
    "        self.subset = subset\n",
    "        self.image_size = image_size\n",
    "        self.color = color\n",
    "        self.rescale = rescale\n",
    "\n",
    "        \n",
    "        # Initialize MNIST dataset\n",
    "        # init memmap batches here\n",
    "        self.mnist_handler = MnistHandler()\n",
    "        print(self.mnist_handler.get_n_samples(subset))\n",
    "        self.n_samples = self.mnist_handler.get_n_samples(subset)\n",
    "        self.n_batches = self.n_samples // batch_size\n",
    "        print(\"samples: \", self.n_samples)\n",
    "        print(\"batches: \", self.n_batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def next(self):\n",
    "\n",
    "        # Get data\n",
    "        x, y = self.mnist_handler.get_batch(self.subset, self.batch_size, self.image_size, self.color, self.rescale)\n",
    "        \n",
    "        # Convert y to one-hot\n",
    "        y_h = np.eye(10)[y]\n",
    "        print(x.shape, y_h.shape)\n",
    "        print(y_h)\n",
    "\n",
    "        return x, y_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortedNumberGenerator(object):\n",
    "\n",
    "    ''' Data generator providing lists of sorted numbers '''\n",
    "\n",
    "    def __init__(self, batch_size, subset, terms, positive_samples=1, predict_terms=1, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Set params\n",
    "        self.positive_samples = positive_samples\n",
    "        self.predict_terms = predict_terms\n",
    "        self.batch_size = batch_size\n",
    "        self.subset = subset\n",
    "        self.terms = terms\n",
    "        self.image_size = image_size\n",
    "        self.color = color\n",
    "        self.rescale = rescale\n",
    "\n",
    "        # Initialize MNIST dataset\n",
    "        self.mnist_handler = MnistHandler()\n",
    "        self.n_samples = self.mnist_handler.get_n_samples(subset) // terms\n",
    "        self.n_batches = self.n_samples // batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def next(self):\n",
    "\n",
    "        # Build sentences\n",
    "        image_labels = np.zeros((self.batch_size, self.terms + self.predict_terms))\n",
    "        sentence_labels = np.ones((self.batch_size, 1)).astype('int32')\n",
    "        positive_samples_n = self.positive_samples\n",
    "        for b in range(self.batch_size):\n",
    "\n",
    "            # Set ordered predictions for positive samples\n",
    "            seed = np.random.randint(0, 10)\n",
    "            sentence = np.mod(np.arange(seed, seed + self.terms + self.predict_terms), 10)\n",
    "\n",
    "            if positive_samples_n <= 0:\n",
    "\n",
    "                # Set random predictions for negative samples\n",
    "                # Each predicted term draws a number from a distribution that excludes itself\n",
    "                numbers = np.arange(0, 10)\n",
    "                predicted_terms = sentence[-self.predict_terms:]\n",
    "                for i, p in enumerate(predicted_terms):\n",
    "                    predicted_terms[i] = np.random.choice(numbers[numbers != p], 1)\n",
    "                sentence[-self.predict_terms:] = np.mod(predicted_terms, 10)\n",
    "                sentence_labels[b, :] = 0\n",
    "\n",
    "            # Save sentence\n",
    "            image_labels[b, :] = sentence\n",
    "\n",
    "            positive_samples_n -= 1\n",
    "\n",
    "        # Retrieve actual images (64, 64, 3) => (32, 2)\n",
    "        # replace\n",
    "        images, _ = self.mnist_handler.get_batch_by_labels(self.subset, image_labels.flatten(), self.image_size, self.color, self.rescale)\n",
    "        print(\"actual images: \", images.shape)\n",
    "        \n",
    "        # Assemble batch\n",
    "        images = images.reshape((self.batch_size, self.terms + self.predict_terms, images.shape[1], images.shape[2], images.shape[3]))\n",
    "        x_images = images[:, :-self.predict_terms, ...]\n",
    "        y_images = images[:, -self.predict_terms:, ...]\n",
    "        print(\"images: \", images.shape)\n",
    "        print(\"x_img: \", x_images.shape)\n",
    "        print(\"y_img: \", y_images.shape)\n",
    "\n",
    "        # Randomize\n",
    "        idxs = np.random.choice(sentence_labels.shape[0], sentence_labels.shape[0], replace=False)\n",
    "        print(\"idx shape: \", idxs.shape)\n",
    "        #print(\"idx: \", idxs)\n",
    "        print(\"sentence_labels shape: \", sentence_labels.shape)\n",
    "        print(\"sentence_labels: \", sentence_labels)\n",
    "        return [x_images[idxs, ...], y_images[idxs, ...]], sentence_labels[idxs, ...], idxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing *all* these objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "samples:  50000\n",
      "batches:  6250\n",
      "(8, 28, 28, 3) (8, 10)\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "(8, 28, 28, 3) (8, 10)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "(8, 28, 28, 3) (8, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-17aaee917525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test MnistGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMnistGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Test MnistGenerator\n",
    "mh, mx = MnistGenerator(batch_size=8, subset='train', image_size=28, color=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual images:  (64, 64, 64, 3)\n",
      "images:  (8, 8, 64, 64, 3)\n",
      "x_img:  (8, 4, 64, 64, 3)\n",
      "y_img:  (8, 4, 64, 64, 3)\n",
      "idx shape:  (8,)\n",
      "sentence_labels shape:  (8, 1)\n",
      "sentence_labels:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "actual images:  (64, 64, 64, 3)\n",
      "images:  (8, 8, 64, 64, 3)\n",
      "x_img:  (8, 4, 64, 64, 3)\n",
      "y_img:  (8, 4, 64, 64, 3)\n",
      "idx shape:  (8,)\n",
      "sentence_labels shape:  (8, 1)\n",
      "sentence_labels:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "actual images:  (64, 64, 64, 3)\n",
      "images:  (8, 8, 64, 64, 3)\n",
      "x_img:  (8, 4, 64, 64, 3)\n",
      "y_img:  (8, 4, 64, 64, 3)\n",
      "idx shape:  (8,)\n",
      "sentence_labels shape:  (8, 1)\n",
      "sentence_labels:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-42f27539fea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test SortedNumberGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSortedNumberGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Test SortedNumberGenerator\n",
    "ag = SortedNumberGenerator(batch_size=8, subset='train', terms=4, positive_samples=4, predict_terms=4, image_size=64, color=True, rescale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SortedNumberGenerator output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual images:  (64, 64, 64, 3)\n",
      "images:  (8, 8, 64, 64, 3)\n",
      "x_img:  (8, 4, 64, 64, 3)\n",
      "y_img:  (8, 4, 64, 64, 3)\n",
      "idx shape:  (8,)\n",
      "sentence_labels shape:  (8, 1)\n",
      "sentence_labels:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "a = next(ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = a[0]\n",
    "img_lbls = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4, 64, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of images (x)\n",
    "np.vstack(imgs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of image labels (y)\n",
    "np.vstack(img_lbls).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4, 64, 64, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "messing with train and validation sets in train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from data_utils import SortedNumberGenerator\n",
    "from os.path import join, basename, dirname, exists\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for examining output - don't reset this cell\n",
    "train_model(\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    output_dir='models/64x64',\n",
    "    code_size=128,\n",
    "    lr=1e-3,\n",
    "    terms=4,\n",
    "    predict_terms=4,\n",
    "    image_size=64,\n",
    "    color=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_encoder(x, code_size):\n",
    "\n",
    "    ''' Define the network mapping images to embeddings '''\n",
    "\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(units=256, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Dense(units=code_size, activation='linear', name='encoder_embedding')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def network_autoregressive(x):\n",
    "\n",
    "    ''' Define the network that integrates information along the sequence '''\n",
    "\n",
    "    # x = keras.layers.GRU(units=256, return_sequences=True)(x)\n",
    "    # x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.GRU(units=256, return_sequences=False, name='ar_context')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def network_prediction(context, code_size, predict_terms):\n",
    "\n",
    "    ''' Define the network mapping context to multiple embeddings '''\n",
    "\n",
    "    outputs = []\n",
    "    for i in range(predict_terms):\n",
    "        outputs.append(keras.layers.Dense(units=code_size, activation=\"linear\", name='z_t_{i}'.format(i=i))(context))\n",
    "\n",
    "    if len(outputs) == 1:\n",
    "        output = keras.layers.Lambda(lambda x: K.expand_dims(x, axis=1))(outputs[0])\n",
    "    else:\n",
    "        output = keras.layers.Lambda(lambda x: K.stack(x, axis=1))(outputs)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class CPCLayer(keras.layers.Layer):\n",
    "\n",
    "    ''' Computes dot product between true and predicted embedding vectors '''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CPCLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # Compute dot product among vectors\n",
    "        preds, y_encoded = inputs\n",
    "        dot_product = K.mean(y_encoded * preds, axis=-1)\n",
    "        dot_product = K.mean(dot_product, axis=-1, keepdims=True)  # average along the temporal dimension\n",
    "\n",
    "        # Keras loss functions take probabilities\n",
    "        dot_product_probs = K.sigmoid(dot_product)\n",
    "\n",
    "        return dot_product_probs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "\n",
    "\n",
    "def network_cpc(image_shape, terms, predict_terms, code_size, learning_rate):\n",
    "\n",
    "    ''' Define the CPC network combining encoder and autoregressive model '''\n",
    "\n",
    "    # Set learning phase (https://stackoverflow.com/questions/42969779/keras-error-you-must-feed-a-value-for-placeholder-tensor-bidirectional-1-keras)\n",
    "    K.set_learning_phase(1)\n",
    "\n",
    "    # Define encoder model\n",
    "    encoder_input = keras.layers.Input(image_shape)\n",
    "    encoder_output = network_encoder(encoder_input, code_size)\n",
    "    encoder_model = keras.models.Model(encoder_input, encoder_output, name='encoder')\n",
    "    encoder_model.summary()\n",
    "\n",
    "    # Define rest of model\n",
    "    x_input = keras.layers.Input((terms, image_shape[0], image_shape[1], image_shape[2]))\n",
    "    x_encoded = keras.layers.TimeDistributed(encoder_model)(x_input)\n",
    "    context = network_autoregressive(x_encoded)\n",
    "    preds = network_prediction(context, code_size, predict_terms)\n",
    "\n",
    "    y_input = keras.layers.Input((predict_terms, image_shape[0], image_shape[1], image_shape[2]))\n",
    "    y_encoded = keras.layers.TimeDistributed(encoder_model)(y_input)\n",
    "\n",
    "    # Loss\n",
    "    dot_product_probs = CPCLayer()([preds, y_encoded])\n",
    "\n",
    "    # Model\n",
    "    cpc_model = keras.models.Model(inputs=[x_input, y_input], outputs=dot_product_probs)\n",
    "\n",
    "    # Compile model\n",
    "    cpc_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    cpc_model.summary()\n",
    "\n",
    "    return cpc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no loss fxn\n",
    "def train_model(epochs, batch_size, output_dir, code_size, lr=1e-4, terms=4, predict_terms=4, image_size=28, color=False):\n",
    "\n",
    "    # Prepare data\n",
    "    train_data = SortedNumberGenerator(batch_size=batch_size, subset='train', terms=terms,\n",
    "                                       positive_samples=batch_size // 2, predict_terms=predict_terms,\n",
    "                                       image_size=image_size, color=color, rescale=True)\n",
    "\n",
    "    validation_data = SortedNumberGenerator(batch_size=batch_size, subset='valid', terms=terms,\n",
    "                                            positive_samples=batch_size // 2, predict_terms=predict_terms,\n",
    "                                            image_size=image_size, color=color, rescale=True)\n",
    "    print(\"training set: \", len(train_data))\n",
    "    print(\"validation set: \", len(validation_data))\n",
    "    \n",
    "    # Prepares the model\n",
    "    model = network_cpc(image_shape=(image_size, image_size, 3), terms=terms, predict_terms=predict_terms,\n",
    "                        code_size=code_size, learning_rate=lr)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=1/3, patience=2, min_lr=1e-4)]\n",
    "\n",
    "    # Trains the model\n",
    "    model.fit_generator(\n",
    "        generator=train_data,\n",
    "        steps_per_epoch=len(train_data),\n",
    "        validation_data=validation_data,\n",
    "        validation_steps=len(validation_data),\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Saves the model\n",
    "    # Remember to add custom_objects={'CPCLayer': CPCLayer} to load_model when loading from disk\n",
    "    model.save(join(output_dir, 'cpc.h5'))\n",
    "\n",
    "    # Saves the encoder alone\n",
    "    encoder = model.layers[1].layer\n",
    "    encoder.save(join(output_dir, 'encoder.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss fxn\n",
    "def train_model(epochs, batch_size, output_dir, code_size, lr=1e-4, terms=4, predict_terms=4, image_size=28, color=False):\n",
    "\n",
    "    # Prepare data\n",
    "    train_data = SortedNumberGenerator(batch_size=batch_size, subset='train', terms=terms,\n",
    "                                       positive_samples=batch_size // 2, predict_terms=predict_terms,\n",
    "                                       image_size=image_size, color=color, rescale=True)\n",
    "\n",
    "    validation_data = SortedNumberGenerator(batch_size=batch_size, subset='valid', terms=terms,\n",
    "                                            positive_samples=batch_size // 2, predict_terms=predict_terms,\n",
    "                                            image_size=image_size, color=color, rescale=True)\n",
    "    print(\"train: \", len(train_data))\n",
    "    #type(train_data).__name__\n",
    "    print(np.shape(next(train_data)[0]))\n",
    "    print(np.shape(next(train_data)[1]))\n",
    "    print(np.shape(next(train_data)[2]))\n",
    "    #print(\"validation: \", len(validation_data))\n",
    "    #print(type(validation_data))\n",
    "    \n",
    "    # Prepares the model\n",
    "    model = network_cpc(image_shape=(image_size, image_size, 3), terms=terms, predict_terms=predict_terms,\n",
    "                        code_size=code_size, learning_rate=lr)\n",
    "\n",
    "    # Callbacks\n",
    "    history = keras.callbacks.History()\n",
    "    reduce_LR_Plateau = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=1/3, \n",
    "        patience=2, \n",
    "        min_lr=1e-4)\n",
    "    #callbacks = [history, reduce_LR_Plateau]\n",
    "    callbacks = [history]\n",
    "    \n",
    "    # Trains the model\n",
    "    modeled = model.fit_generator(\n",
    "        generator=train_data,\n",
    "        steps_per_epoch=len(train_data),\n",
    "        validation_data=validation_data,\n",
    "        validation_steps=len(validation_data),\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Saves the model\n",
    "    # Remember to add custom_objects={'CPCLayer': CPCLayer} to load_model when loading from disk\n",
    "    model.save(join(output_dir, 'cpc.h5'))\n",
    "\n",
    "    # Saves the encoder alone\n",
    "    encoder = model.layers[1].layer\n",
    "    encoder.save(join(output_dir, 'encoder.h5'))\n",
    "    \n",
    "    # plotting loss\n",
    "    train_loss = modeled.history['loss']\n",
    "    val_loss = modeled.history['val_loss']\n",
    "    epoch_count = range(1, epochs+1)    # 10 epochs\n",
    "\n",
    "    plt.plot(epoch_count, train_loss, 'r--')\n",
    "    plt.plot(epoch_count, val_loss, 'o-')\n",
    "    plt.legend(['Training Loss', 'Validation Loss'])\n",
    "    plt.title('')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    t = time.localtime()\n",
    "    timestamp = time.strftime('%b-%d-%Y_%H%M', t)\n",
    "    plt.savefig(output_dir + \"img/\" + timestamp + \".png\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ratio(train, val):\n",
    "    ''' find train/validation set split '''\n",
    "    total = train + val\n",
    "    train_ratio = train/total\n",
    "    val_ratio = val/total\n",
    "    return \"total training set: \" + str(total), \"training: \" + str(train_ratio), \"validation: \" + str(val_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('total training set: 468',\n",
       " 'training: 0.8333333333333334',\n",
       " 'validation: 0.16666666666666666')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding training + validation set size\n",
    "find_ratio(390, 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding test set size\n",
    "test = SortedNumberGenerator(batch_size=8, subset='test', terms=4, positive_samples=4, predict_terms=4, image_size=64, color=True, rescale=False)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.92848008753788"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total data - if 28x28, should be 784 but is 780\n",
    "# and is actually 64x64???\n",
    "import math\n",
    "\n",
    "dataset = 312 + 468   # 780 - from printing train_data and validation_data in train_model()\n",
    "math.sqrt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  781\n",
      "actual images:  (128, 64, 64, 3)\n",
      "images:  (16, 8, 64, 64, 3)\n",
      "x_img:  (16, 4, 64, 64, 3)\n",
      "y_img:  (16, 4, 64, 64, 3)\n",
      "idx shape:  (16,)\n",
      "sentence_labels shape:  (16, 1)\n",
      "sentence_labels:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "(2, 16, 4, 64, 64, 3)\n",
      "actual images:  (128, 64, 64, 3)\n",
      "images:  (16, 8, 64, 64, 3)\n",
      "x_img:  (16, 4, 64, 64, 3)\n",
      "y_img:  (16, 4, 64, 64, 3)\n",
      "idx shape:  (16,)\n",
      "sentence_labels shape:  (16, 1)\n",
      "sentence_labels:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "(16, 1)\n",
      "actual images:  (128, 64, 64, 3)\n",
      "images:  (16, 8, 64, 64, 3)\n",
      "x_img:  (16, 4, 64, 64, 3)\n",
      "y_img:  (16, 4, 64, 64, 3)\n",
      "idx shape:  (16,)\n",
      "sentence_labels shape:  (16, 1)\n",
      "sentence_labels:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "(16,)\n",
      "WARNING:tensorflow:From /home/AD/kachiem/miniconda3/envs/tf-conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 31, 31, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 31, 31, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "encoder_embedding (Dense)    (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 295,232\n",
      "Trainable params: 294,208\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 4, 64, 64, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 4, 128)       295232      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ar_context (GRU)                (None, 256)          295680      time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "z_t_0 (Dense)                   (None, 128)          32896       ar_context[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_t_1 (Dense)                   (None, 128)          32896       ar_context[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_t_2 (Dense)                   (None, 128)          32896       ar_context[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_t_3 (Dense)                   (None, 128)          32896       ar_context[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 4, 64, 64, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 4, 128)       0           z_t_0[0][0]                      \n",
      "                                                                 z_t_1[0][0]                      \n",
      "                                                                 z_t_2[0][0]                      \n",
      "                                                                 z_t_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 4, 128)       295232      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cpc_layer (CPCLayer)            (None, 1)            0           lambda[0][0]                     \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 721,472\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SortedNumberGenerator' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e4f3c6dd8e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpredict_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-19-9f7d0f11b832>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, batch_size, output_dir, code_size, lr, terms, predict_terms, image_size, color)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tf-conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m       shuffle=shuffle)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mconvert_to_generator_like\u001b[0;34m(data, batch_size, steps_per_epoch, epochs, shuffle)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;31m# Create generator from NumPy or EagerTensor Input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m   \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You must specify `batch_size`'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SortedNumberGenerator' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# train here - single GRU\n",
    "train_model(\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    output_dir='../models/64x64',\n",
    "    code_size=128,\n",
    "    lr=1e-3,\n",
    "    terms=4,\n",
    "    predict_terms=4,\n",
    "    image_size=64,\n",
    "    color=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display loss\n",
    "import IPython\n",
    "IPython.display.Image(filename=\"/home/AD/kachiem/github/contrastive-predictive-coding/models/64x64/loss/Nov-15-2019_0331.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
