{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exploring MnistHandler, MnistGenerator, and SortedNumberGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistHandler(object):\n",
    "\n",
    "    ''' Provides a convenient interface to manipulate MNIST data '''\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Download data if needed\n",
    "        self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test = self.load_dataset()\n",
    "\n",
    "        # Load Lena image to memory\n",
    "        self.lena = Image.open('../resources/lena.jpg')\n",
    "\n",
    "    def load_dataset(self):\n",
    "        # Credit for this function: https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py\n",
    "\n",
    "        # We first define a download function, supporting both Python 2 and 3.\n",
    "        if sys.version_info[0] == 2:\n",
    "            from urllib import urlretrieve\n",
    "        else:\n",
    "            #from urllib.request import urlretrieve\n",
    "            import requests\n",
    "\n",
    "        def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "            print(\"Downloading %s\" % filename)\n",
    "            requests.get(source + filename, filename)\n",
    "\n",
    "        # We then define functions for loading MNIST images and labels.\n",
    "        # For convenience, they also download the requested files if needed.\n",
    "        import gzip\n",
    "\n",
    "        def load_mnist_images(filename):\n",
    "            if not os.path.exists(filename):\n",
    "                download(filename)\n",
    "            # Read the inputs in Yann LeCun's binary format.\n",
    "            with gzip.open(filename, 'rb') as f:\n",
    "                data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "            # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "            # following the shape convention: (examples, channels, rows, columns)\n",
    "            data = data.reshape(-1, 1, 28, 28)\n",
    "            # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "            # (Actually to range [0, 255/256], for compatibility to the version\n",
    "            # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "            return data / np.float32(256)\n",
    "\n",
    "        def load_mnist_labels(filename):\n",
    "            if not os.path.exists(filename):\n",
    "                download(filename)\n",
    "            # Read the labels in Yann LeCun's binary format.\n",
    "            with gzip.open(filename, 'rb') as f:\n",
    "                data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "            # The labels are vectors of integers now, that's exactly what we want.\n",
    "            return data\n",
    "\n",
    "        # We can now download and read the training and test set images and labels.\n",
    "        X_train = load_mnist_images('../resources/train-images-idx3-ubyte.gz')\n",
    "        y_train = load_mnist_labels('../resources/train-labels-idx1-ubyte.gz')\n",
    "        X_test = load_mnist_images('../resources/t10k-images-idx3-ubyte.gz')\n",
    "        y_test = load_mnist_labels('../resources/t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "        # We reserve the last 10000 training examples for validation.\n",
    "        X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "        y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "        # We just return all the arrays in order, as expected in main().\n",
    "        # (It doesn't matter how we do this as long as we can read them again.)\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "    def process_batch(self, batch, batch_size, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Resize from 28x28 to 64x64\n",
    "        if image_size == 64:\n",
    "            batch_resized = []\n",
    "            for i in range(batch.shape[0]):\n",
    "                # resize to 64x64 pixels\n",
    "                batch_resized.append(scipy.ndimage.zoom(batch[i, :, :], 2.3, order=1))\n",
    "            batch = np.stack(batch_resized)\n",
    "\n",
    "        # Convert to RGB\n",
    "        batch = batch.reshape((batch_size, 1, image_size, image_size))\n",
    "        batch = np.concatenate([batch, batch, batch], axis=1)\n",
    "\n",
    "        # Modify images if color distribution requested\n",
    "        if color:\n",
    "\n",
    "            # Binarize images\n",
    "            batch[batch >= 0.5] = 1\n",
    "            batch[batch < 0.5] = 0\n",
    "\n",
    "            # For each image in the mini batch\n",
    "            for i in range(batch_size):\n",
    "\n",
    "                # Take a random crop of the Lena image (background)\n",
    "                x_c = np.random.randint(0, self.lena.size[0] - image_size)\n",
    "                y_c = np.random.randint(0, self.lena.size[1] - image_size)\n",
    "                image = self.lena.crop((x_c, y_c, x_c + image_size, y_c + image_size))\n",
    "                image = np.asarray(image).transpose((2, 0, 1)) / 255.0\n",
    "\n",
    "                # Randomly alter the color distribution of the crop\n",
    "                for j in range(3):\n",
    "                    image[j, :, :] = (image[j, :, :] + np.random.uniform(0, 1)) / 2.0\n",
    "\n",
    "                # Invert the color of pixels where there is a number\n",
    "                image[batch[i, :, :, :] == 1] = 1 - image[batch[i, :, :, :] == 1]\n",
    "                batch[i, :, :, :] = image\n",
    "\n",
    "        # Rescale to range [-1, +1]\n",
    "        if rescale:\n",
    "            batch = batch * 2 - 1\n",
    "\n",
    "        # Channel last\n",
    "        batch = batch.transpose((0, 2, 3, 1))\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def get_batch(self, subset, batch_size, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Select a subset\n",
    "        if subset == 'train':\n",
    "            X = self.X_train\n",
    "            y = self.y_train\n",
    "        elif subset == 'valid':\n",
    "            X = self.X_val\n",
    "            y = self.y_val\n",
    "        elif subset == 'test':\n",
    "            X = self.X_test\n",
    "            y = self.y_test\n",
    "\n",
    "        # Random choice of samples\n",
    "        idx = np.random.choice(X.shape[0], batch_size)\n",
    "        batch = X[idx, 0, :].reshape((batch_size, 28, 28))\n",
    "\n",
    "        # Process batch\n",
    "        batch = self.process_batch(batch, batch_size, image_size, color, rescale)\n",
    "\n",
    "        # Image label\n",
    "        labels = y[idx]\n",
    "\n",
    "        return batch.astype('float32'), labels.astype('int32')\n",
    "\n",
    "    def get_batch_by_labels(self, subset, labels, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Select a subset\n",
    "        if subset == 'train':\n",
    "            X = self.X_train\n",
    "            y = self.y_train\n",
    "        elif subset == 'valid':\n",
    "            X = self.X_val\n",
    "            y = self.y_val\n",
    "        elif subset == 'test':\n",
    "            X = self.X_test\n",
    "            y = self.y_test\n",
    "\n",
    "        # Find samples matching labels\n",
    "        idxs = []\n",
    "        for i, label in enumerate(labels):\n",
    "\n",
    "            idx = np.where(y == label)[0]\n",
    "            idx_sel = np.random.choice(idx, 1)[0]\n",
    "            idxs.append(idx_sel)\n",
    "\n",
    "        # Retrieve images\n",
    "        batch = X[np.array(idxs), 0, :].reshape((len(labels), 28, 28))\n",
    "\n",
    "        # Process batch\n",
    "        batch = self.process_batch(batch, len(labels), image_size, color, rescale)\n",
    "\n",
    "        return batch.astype('float32'), labels.astype('int32')\n",
    "\n",
    "    def get_n_samples(self, subset):\n",
    "\n",
    "        if subset == 'train':\n",
    "            y_len = self.y_train.shape[0]\n",
    "        elif subset == 'valid':\n",
    "            y_len = self.y_val.shape[0]\n",
    "        elif subset == 'test':\n",
    "            y_len = self.y_test.shape[0]\n",
    "\n",
    "        return y_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemmapHandler(object):\n",
    "\n",
    "    ''' Provides a convenient interface to manipulate memmap data (.dat) '''\n",
    "    \n",
    "    def __init__(self):\n",
    "         self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test = self.load_memmap_data()\n",
    "\n",
    "    def load_memmap_data(dirname):\n",
    "        if not os.path.exists(dirname):\n",
    "            print(\"cannot find memmap data.\")\n",
    "        # read in directory of .dat files.\n",
    "        file_List = os.listdir(dirname)\n",
    "        for file in file_list:\n",
    "            file = np.fromfile('%sx_lag%03d.dat' % (datafolder, n_lags), dtype=dt)\n",
    "            data = np.frombuffer(file.read(), np.uint8, offset=16)\n",
    "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "        # following the shape convention: (examples, channels, rows, columns)\n",
    "        data = data.reshape(-1, 1, 28, 28)\n",
    "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "        # (Actually to range [0, 255/256], for compatibility to the version\n",
    "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "\n",
    "        # We can now download and read the training and test set images and labels.\n",
    "        train = load_memmap_data('../resources/memmap_dataset_stimulus/')\n",
    "        test = load_memmap_data('../resources/memmap_dataset_stimulus_vis/')\n",
    "        \n",
    "        # 80/20 train/test split\n",
    "        # reserve additional 10% of training files for validation (2 files)\n",
    "        X_train, X_test = train[:-2], train[-2:]\n",
    "        y_train, y_test = test[:-2], test[-2:]\n",
    "\n",
    "        # We reserve the last 2 training examples for validation.\n",
    "        X_train, X_val = X_train[:-2], X_train[-2:]\n",
    "        y_train, y_val = y_train[:-2], y_train[-2:]\n",
    "\n",
    "        # We just return all the arrays in order, as expected in main().\n",
    "        # (It doesn't matter how we do this as long as we can read them again.)\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistGenerator(object):\n",
    "\n",
    "    ''' Data generator providing MNIST data '''\n",
    "\n",
    "    def __init__(self, batch_size, subset, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Set params\n",
    "        self.batch_size = batch_size\n",
    "        self.subset = subset\n",
    "        self.image_size = image_size\n",
    "        self.color = color\n",
    "        self.rescale = rescale\n",
    "\n",
    "        # Initialize MNIST dataset\n",
    "        self.mnist_handler = MnistHandler()\n",
    "        self.n_samples = self.mnist_handler.get_n_samples(subset)\n",
    "        self.n_batches = self.n_samples // batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def next(self):\n",
    "\n",
    "        # Get data\n",
    "        x, y = self.mnist_handler.get_batch(self.subset, self.batch_size, self.image_size, self.color, self.rescale)\n",
    "        \n",
    "        # Convert y to one-hot\n",
    "        y_h = np.eye(10)[y]\n",
    "        print(x.shape, y_h.shape)\n",
    "        print(y_h)\n",
    "\n",
    "        return x, y_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortedNumberGenerator(object):\n",
    "\n",
    "    ''' Data generator providing lists of sorted numbers '''\n",
    "\n",
    "    def __init__(self, batch_size, subset, terms, positive_samples=1, predict_terms=1, image_size=28, color=False, rescale=True):\n",
    "\n",
    "        # Set params\n",
    "        self.positive_samples = positive_samples\n",
    "        self.predict_terms = predict_terms\n",
    "        self.batch_size = batch_size\n",
    "        self.subset = subset\n",
    "        self.terms = terms\n",
    "        self.image_size = image_size\n",
    "        self.color = color\n",
    "        self.rescale = rescale\n",
    "\n",
    "        # Initialize MNIST dataset\n",
    "        self.mnist_handler = MnistHandler()\n",
    "        self.n_samples = self.mnist_handler.get_n_samples(subset) // terms\n",
    "        self.n_batches = self.n_samples // batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def next(self):\n",
    "\n",
    "        # Build sentences\n",
    "        image_labels = np.zeros((self.batch_size, self.terms + self.predict_terms))\n",
    "        sentence_labels = np.ones((self.batch_size, 1)).astype('int32')\n",
    "        positive_samples_n = self.positive_samples\n",
    "        for b in range(self.batch_size):\n",
    "\n",
    "            # Set ordered predictions for positive samples\n",
    "            seed = np.random.randint(0, 10)\n",
    "            sentence = np.mod(np.arange(seed, seed + self.terms + self.predict_terms), 10)\n",
    "\n",
    "            if positive_samples_n <= 0:\n",
    "\n",
    "                # Set random predictions for negative samples\n",
    "                # Each predicted term draws a number from a distribution that excludes itself\n",
    "                numbers = np.arange(0, 10)\n",
    "                predicted_terms = sentence[-self.predict_terms:]\n",
    "                for i, p in enumerate(predicted_terms):\n",
    "                    predicted_terms[i] = np.random.choice(numbers[numbers != p], 1)\n",
    "                sentence[-self.predict_terms:] = np.mod(predicted_terms, 10)\n",
    "                sentence_labels[b, :] = 0\n",
    "\n",
    "            # Save sentence\n",
    "            image_labels[b, :] = sentence\n",
    "\n",
    "            positive_samples_n -= 1\n",
    "\n",
    "        # Retrieve actual images\n",
    "        images, _ = self.mnist_handler.get_batch_by_labels(self.subset, image_labels.flatten(), self.image_size, self.color, self.rescale)\n",
    "\n",
    "        # Assemble batch\n",
    "        images = images.reshape((self.batch_size, self.terms + self.predict_terms, images.shape[1], images.shape[2], images.shape[3]))\n",
    "        x_images = images[:, :-self.predict_terms, ...]\n",
    "        y_images = images[:, -self.predict_terms:, ...]\n",
    "        #print(\"x_img: \", x_images.shape)\n",
    "        #print(\"y_img: \", y_images.shape)\n",
    "\n",
    "        # Randomize\n",
    "        idxs = np.random.choice(sentence_labels.shape[0], sentence_labels.shape[0], replace=False)\n",
    "        #print(\"idx shape: \", idxs.shape)\n",
    "        #print(\"idx: \", idxs)\n",
    "        \n",
    "        return [x_images[idxs, ...], y_images[idxs, ...]], sentence_labels[idxs, ...], idxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing *all* these objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 28, 28, 3) (8, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(8, 28, 28, 3) (8, 10)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "(8, 28, 28, 3) (8, 10)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-17aaee917525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test MnistGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMnistGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Test MnistGenerator\n",
    "mh, mx = MnistGenerator(batch_size=8, subset='train', image_size=28, color=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SortedNumberGenerator\n",
    "ag = SortedNumberGenerator(batch_size=8, subset='train', terms=4, positive_samples=4, predict_terms=4, image_size=64, color=True, rescale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SortedNumberGenerator output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = a[0]\n",
    "img_lbls = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4, 64, 64, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of images (x)\n",
    "np.vstack(imgs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of image labels (y)\n",
    "np.vstack(img_lbls).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4, 64, 64, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "messing with train and validation sets in train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from data_utils import SortedNumberGenerator\n",
    "from os.path import join, basename, dirname, exists\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for examining output - don't reset this cell\n",
    "train_model(\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    output_dir='models/64x64',\n",
    "    code_size=128,\n",
    "    lr=1e-3,\n",
    "    terms=4,\n",
    "    predict_terms=4,\n",
    "    image_size=64,\n",
    "    color=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_encoder(x, code_size):\n",
    "\n",
    "    ''' Define the network mapping images to embeddings '''\n",
    "\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(units=256, activation='linear')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Dense(units=code_size, activation='linear', name='encoder_embedding')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def network_autoregressive(x):\n",
    "\n",
    "    ''' Define the network that integrates information along the sequence '''\n",
    "\n",
    "    # x = keras.layers.GRU(units=256, return_sequences=True)(x)\n",
    "    # x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.GRU(units=256, return_sequences=False, name='ar_context')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def network_prediction(context, code_size, predict_terms):\n",
    "\n",
    "    ''' Define the network mapping context to multiple embeddings '''\n",
    "\n",
    "    outputs = []\n",
    "    for i in range(predict_terms):\n",
    "        outputs.append(keras.layers.Dense(units=code_size, activation=\"linear\", name='z_t_{i}'.format(i=i))(context))\n",
    "\n",
    "    if len(outputs) == 1:\n",
    "        output = keras.layers.Lambda(lambda x: K.expand_dims(x, axis=1))(outputs[0])\n",
    "    else:\n",
    "        output = keras.layers.Lambda(lambda x: K.stack(x, axis=1))(outputs)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class CPCLayer(keras.layers.Layer):\n",
    "\n",
    "    ''' Computes dot product between true and predicted embedding vectors '''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CPCLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # Compute dot product among vectors\n",
    "        preds, y_encoded = inputs\n",
    "        dot_product = K.mean(y_encoded * preds, axis=-1)\n",
    "        dot_product = K.mean(dot_product, axis=-1, keepdims=True)  # average along the temporal dimension\n",
    "\n",
    "        # Keras loss functions take probabilities\n",
    "        dot_product_probs = K.sigmoid(dot_product)\n",
    "\n",
    "        return dot_product_probs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "\n",
    "\n",
    "def network_cpc(image_shape, terms, predict_terms, code_size, learning_rate):\n",
    "\n",
    "    ''' Define the CPC network combining encoder and autoregressive model '''\n",
    "\n",
    "    # Set learning phase (https://stackoverflow.com/questions/42969779/keras-error-you-must-feed-a-value-for-placeholder-tensor-bidirectional-1-keras)\n",
    "    K.set_learning_phase(1)\n",
    "\n",
    "    # Define encoder model\n",
    "    encoder_input = keras.layers.Input(image_shape)\n",
    "    encoder_output = network_encoder(encoder_input, code_size)\n",
    "    encoder_model = keras.models.Model(encoder_input, encoder_output, name='encoder')\n",
    "    encoder_model.summary()\n",
    "\n",
    "    # Define rest of model\n",
    "    x_input = keras.layers.Input((terms, image_shape[0], image_shape[1], image_shape[2]))\n",
    "    x_encoded = keras.layers.TimeDistributed(encoder_model)(x_input)\n",
    "    context = network_autoregressive(x_encoded)\n",
    "    preds = network_prediction(context, code_size, predict_terms)\n",
    "\n",
    "    y_input = keras.layers.Input((predict_terms, image_shape[0], image_shape[1], image_shape[2]))\n",
    "    y_encoded = keras.layers.TimeDistributed(encoder_model)(y_input)\n",
    "\n",
    "    # Loss\n",
    "    dot_product_probs = CPCLayer()([preds, y_encoded])\n",
    "\n",
    "    # Model\n",
    "    cpc_model = keras.models.Model(inputs=[x_input, y_input], outputs=dot_product_probs)\n",
    "\n",
    "    # Compile model\n",
    "    cpc_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    cpc_model.summary()\n",
    "\n",
    "    return cpc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, batch_size, output_dir, code_size, lr=1e-4, terms=4, predict_terms=4, image_size=28, color=False):\n",
    "\n",
    "    # Prepare data\n",
    "    train_data = SortedNumberGenerator(batch_size=batch_size, subset='train', terms=terms,\n",
    "                                       positive_samples=batch_size // 2, predict_terms=predict_terms,\n",
    "                                       image_size=image_size, color=color, rescale=True)\n",
    "\n",
    "    validation_data = SortedNumberGenerator(batch_size=batch_size, subset='valid', terms=terms,\n",
    "                                            positive_samples=batch_size // 2, predict_terms=predict_terms,\n",
    "                                            image_size=image_size, color=color, rescale=True)\n",
    "    print(\"training set: \", len(train_data))\n",
    "    print(\"validation set: \", len(validation_data))\n",
    "    \n",
    "    # Prepares the model\n",
    "    model = network_cpc(image_shape=(image_size, image_size, 3), terms=terms, predict_terms=predict_terms,\n",
    "                        code_size=code_size, learning_rate=lr)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=1/3, patience=2, min_lr=1e-4)]\n",
    "\n",
    "    # Trains the model\n",
    "    model.fit_generator(\n",
    "        generator=train_data,\n",
    "        steps_per_epoch=len(train_data),\n",
    "        validation_data=validation_data,\n",
    "        validation_steps=len(validation_data),\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Saves the model\n",
    "    # Remember to add custom_objects={'CPCLayer': CPCLayer} to load_model when loading from disk\n",
    "    model.save(join(output_dir, 'cpc.h5'))\n",
    "\n",
    "    # Saves the encoder alone\n",
    "    encoder = model.layers[1].layer\n",
    "    encoder.save(join(output_dir, 'encoder.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ratio(train, val):\n",
    "    ''' find train/validation set split '''\n",
    "    total = train + val\n",
    "    train_ratio = train/total\n",
    "    val_ratio = val/total\n",
    "    return \"total training set: \" + str(total), \"training: \" + str(train_ratio), \"validation: \" + str(val_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('total training set: 468',\n",
       " 'training: 0.8333333333333334',\n",
       " 'validation: 0.16666666666666666')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding training + validation set size\n",
    "find_ratio(390, 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding test set size\n",
    "test = SortedNumberGenerator(batch_size=8, subset='test', terms=4, positive_samples=4, predict_terms=4, image_size=64, color=True, rescale=False)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total data - if 28x28, should be 784 but is 780\n",
    "# and is actually 64x64???\n",
    "dataset = 312 + 468   # 780\n",
    "sqrt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set:  390\n",
      "validation set:  78\n",
      "WARNING:tensorflow:From /home/AD/kachiem/miniconda3/envs/tf-conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 31, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 31, 31, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "encoder_embedding (Dense)    (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 295,232\n",
      "Trainable params: 294,208\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 4, 64, 64, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 4, 128)       295232      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ar_context (GRU)                (None, 256)          295680      time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "z_t_0 (Dense)                   (None, 128)          32896       ar_context[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_t_1 (Dense)                   (None, 128)          32896       ar_context[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_t_2 (Dense)                   (None, 128)          32896       ar_context[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_t_3 (Dense)                   (None, 128)          32896       ar_context[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 4, 64, 64, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4, 128)       0           z_t_0[0][0]                      \n",
      "                                                                 z_t_1[0][0]                      \n",
      "                                                                 z_t_2[0][0]                      \n",
      "                                                                 z_t_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 4, 128)       295232      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cpc_layer_1 (CPCLayer)          (None, 1)            0           lambda_1[0][0]                   \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 721,472\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/AD/kachiem/miniconda3/envs/tf-conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 9.0117 - binary_accuracy: 0.4999 - val_loss: 8.9070 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 8.9087 - binary_accuracy: 0.5000 - val_loss: 8.8692 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 8.8787 - binary_accuracy: 0.5000 - val_loss: 8.8660 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 8.8803 - binary_accuracy: 0.5000 - val_loss: 8.9031 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 8.8742 - binary_accuracy: 0.5000 - val_loss: 8.8738 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 8.8645 - binary_accuracy: 0.5000 - val_loss: 8.8543 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 8.8671 - binary_accuracy: 0.5000 - val_loss: 8.8474 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 8.8613 - binary_accuracy: 0.5000 - val_loss: 8.8773 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 8.8605 - binary_accuracy: 0.5000 - val_loss: 8.8574 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 8.8638 - binary_accuracy: 0.5000 - val_loss: 8.8491 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'models/64x64/cpc.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5cba41c36622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpredict_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-16-055d8ece9f28>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, batch_size, output_dir, code_size, lr, terms, predict_terms, image_size, color)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Saves the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Remember to add custom_objects={'CPCLayer': CPCLayer} to load_model when loading from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cpc.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Saves the encoder alone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-conda/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-conda/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-conda/lib/python3.7/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-conda/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-conda/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'models/64x64/cpc.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "# train here - single GRU\n",
    "train_model(\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    output_dir='models/64x64',\n",
    "    code_size=128,\n",
    "    lr=1e-3,\n",
    "    terms=4,\n",
    "    predict_terms=4,\n",
    "    image_size=64,\n",
    "    color=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
